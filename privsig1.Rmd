---
title: "priv sig 1"
output: html_document
date: "2022-12-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(rvest)
```


```{r}
pages <- c(
'https://github.com/orgs/folio-org/repositories?page=1',
'https://github.com/orgs/folio-org/repositories?page=2',
'https://github.com/orgs/folio-org/repositories?page=3',
'https://github.com/orgs/folio-org/repositories?page=4',
'https://github.com/orgs/folio-org/repositories?page=5',
'https://github.com/orgs/folio-org/repositories?page=6',
'https://github.com/orgs/folio-org/repositories?page=7',
'https://github.com/orgs/folio-org/repositories?page=8',
'https://github.com/orgs/folio-org/repositories?page=9',
'https://github.com/orgs/folio-org/repositories?page=10',
'https://github.com/orgs/folio-org/repositories?page=11'
)

pages_sample <- c(
'https://github.com/orgs/folio-org/repositories?page=1',
'https://github.com/orgs/folio-org/repositories?page=2'
)


```

## pull navigation pages
```{r}
out <- vector("list", length(pages_sample))
for (i in seq_along(pages_sample)) {
  df1 <- read_html(pages_sample[[i]]) %>% 
    html_elements("a") %>% 
    html_attr("href")
  out[[i]] <- df1
}
```


## Create dataframe
```{r}
all_href <- unlist(out)
df_all_href <- tibble(
  rawlinks = all_href
)

# https://github.com/folio-org/folio-integration-tests
# https://github.com/folio-org/mod-inn-reach/blob/master/PERSONAL_DATA_DISCLOSURE.md

df_repos <- df_all_href %>%
  filter(str_detect(rawlinks, "/folio-org/")) %>%
  filter(str_count(rawlinks, "/") == 2) %>%
  arrange(rawlinks) %>%
  mutate(todays_date = format(Sys.time(), "%Y-%m-%e"),
         repo_key = rawlinks,
         repo_url = paste0("https://github.com", repo_key),
         pdd_url = paste0(repo_url, "/blob/master/PERSONAL_DATA_DISCLOSURE.md"),
         pdd_lastmod_date = NA,
         pdd_declared = NA,
         pdd_rawhtml = NA,
         repo_manager = NA
  ) %>%
  select(-rawlinks)

```


```{r}
read_url <- function(url) {
    out <- tryCatch(
        {
            #message("This is the 'try' part")
            url %>% 
            as.character() %>% read_html() 
        },
        error=function(cond) {
            #message(paste("URL does not seem to exist:", url))
            #message("Here's the original error message:")
            #message(cond)
            return(NA)
        }
    )    
    return(out)
}

test_df_repos <- df_repos %>%
  sample_n(1)

test_df_repos

present_test_df_repos <- test_df_repos

testdata <- bind_rows(present_test_df_repos, missing_test_df_repos)

testdata

for( i in 1:nrow(testdata)) {
  testdata$pdd_rawhtml[i] <- read_url(testdata$pdd_url[i])
}


testdata$pdd_rawhtml[1] %>%
  html_text()
```



```{r}

test_df_repos

#missing pdd file
missingfileexample <- "https://github.com/folio-org/ui-finc-config/blob/master/PERSONAL_DATA_DISCLOSURE.md"

presentfile <- "https://github.com/folio-org/mod-inn-reach/blob/master/PERSONAL_DATA_DISCLOSURE.md"

get_raw_page <- function(url) {
  ret <- read_html(url)
  return(ret)
}



```




```{r}
# reading PDD example


pdd_example <- "https://github.com/folio-org/mod-orders/blob/master/PERSONAL_DATA_DISCLOSURE.md"

pdd_example_raw <- "https://raw.githubusercontent.com/folio-org/mod-orders/master/PERSONAL_DATA_DISCLOSURE.md"

example_html <- read_html(pdd_example)
example_html_raw <- read_html(pdd_example_raw)

download.file(pdd_example_raw, "input/pdd_example_raw.txt")
download.file(pdd_example, "input/pdd_example.html")


filefromdisk <- read_file("input/pdd_example_raw.txt")

df_filefromdisk <- tibble(
  rawlines = filefromdisk
)

df_filefromdisk %>%
  mutate(str_split(rawlines, "\r\n"))

file_commits <- read_html(pdd_example)

# works! Just need to parse this text with regex to get commit date.
file_commits %>%
  html_text2()


read_html(pdd_example) %>%
  html_elements("span.d-md-inline > span:nth-child(3)")
  #html_text2()


```

```{r}
what <- readLines("input/pdd_example_raw.txt")

df_what <- tibble(
  rawline = what
)

df_what %>%
  filter(str_detect(rawline, "This module does not store any personal data"))


readLines(pdd_example_raw)

df_what2 <- tibble(
  rawline = readLines(pdd_example_raw)
)

df_what2 %>%
  filter(str_detect(rawline, "\\[x\\]"))

```
# Now I have a plan

Next Steps:
DONE Create pdd raw test files for all expected conditions:
- no file
- file but no pd
- file with one pd
- file with more than one pd

DONE Add test files to https://github.com/alc28/privsig

Create a test df with the urls of the test files.




```{r}
df_testfiles <- tibble(
  id = 1:4,
  pd_declarations = NA,
  test_pdd_file = c("https://github.com/alc28/privsig/blob/main/test_files/PERSONAL_DATA_DISCLOSURE_no_pd.md", "https://github.com/alc28/privsig/blob/main/test_files/PERSONAL_DATA_DISCLOSURE_one_pd_line.md", "https://github.com/alc28/privsig/blob/main/test_files/PERSONAL_DATA_DISCLOSURE_multiple_pd_line.md", "https://github.com/alc28/privsig/blob/main/test_files/PERSONAL_DATA_DISCLOSURE_missing_pdd.md"),
  test_pdd_file_history = c("https://github.com/alc28/privsig/commits/main/test_files/PERSONAL_DATA_DISCLOSURE_no_pd.md", "https://github.com/alc28/privsig/commits/main/test_files/PERSONAL_DATA_DISCLOSURE_one_pd_line.md", "https://github.com/alc28/privsig/commits/main/test_files/PERSONAL_DATA_DISCLOSURE_multiple_pd_line.md", "https://github.com/alc28/privsig/commits/main/test_files/PERSONAL_DATA_DISCLOSURE_missing_pdd.md"),
  test_pdd_last_commit = NA
)
```

Write standalone function to process test files
- Return either NA or concatenated strings of pd lines retrieved

```{r}

parse_pdd_md <- function(url) {
  raw_html_return <- read_html(url) %>%
  html_text()
  text2 <- str_extract_all(raw_html_return, "\\[[x|X]\\].*\n") %>% unlist() %>% str_remove_all(., "\n")
  return(text2)
}


read_url <- function(url) {
    out <- tryCatch(
        {
            #message("This is the 'try' part")
            parse_pdd_md(url) 
        },
        error=function(cond) {
            #message(paste("URL does not seem to exist:", url))
            #message("Here's the original error message:")
            #message(cond)
            return(NA)
        }
    )    
    return(out)
}



read_url("https://raw.githubusercontent.com/alc28/privsig/main/test_files/PERSONAL_DATA_DISCLOSURE_no_pd.md")

read_url("https://raw.githubusercontent.com/alc28/privsig/main/test_files/PERSONAL_DATA_DISCLOSURE_missing_pd.md")


```


Revise df_repos dataframe creation to get the url of pdd raw version.

Write loop 3 to pull in results of pdd raw across df_repos

Write function to parse the pdd raw history page to get last commit date

<!-- <div class="TimelineItem-body"> -->
<!--             <h2 class="f5 text-normal" >Commits on Jan 1, 2023</h2> -->


Write loop to pull in commit dates

How to identify folio repos that are in production?




